\documentclass[twocolumn,aps,prd,reprint,superscriptaddress]{revtex4-1}
\usepackage{blindtext}
%\usepackage[justification=centering]{caption}
\usepackage{graphics,setspace,enumitem,graphicx,textpos,placeins,float}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{longtable}
\newcommand*{\thead}[1]{\multicolumn{1}{c}{\bfseries #1}}
\newcommand{\q}[1]{``#1''}
\begin{document}
	\graphicspath{{KaustuvDatta/}}
	\bibliographystyle{plain}
	\title{Deep learning algorithms for photon reconstruction and identification in a highly granular calorimeter}
	\author{Kaustuv Datta}
	\affiliation{Reed College}
	\email{dattak@reed.edu}
	%\affiliation{California Institute of Technology}
	
	\author{Jayesh Mahapatra}
	\affiliation{CERN}
	
	\author{Maurizio Pierini}
	\affiliation{CERN}
	
	\author{Maria Spiropulu}
	\affiliation{California Institute of Technology}
	
	\author{Jean-Roch Vlimant}
	\affiliation{California Institute of Technology}

	%\begin{spacing}{1.2}
	
	\begin{abstract}
		A case is made for deep learning to be considered in the development of next generation reconstruction and particle identification techniques. Here, the veracity of such machine learning algorithms is considered, specifically for a highly granular calorimeter geometry, using the Linear Collider Dataset (LCD) dataset created in the CLIC open-source framework. Multiple neural network topologies were tested in the solution of classification problems (capability of discrimination between pion and photon events) and energy regression. Models capable of solving solve both the classification and regression problems were also used. The performances of these different topologies are presented here, along with a discussion of the recent initiative to release our dataset to the public, to create a HEP equivalent of the commonly used MNIST handwriting dataset. 
	\end{abstract}
	\maketitle
	
	
	\section{Introduction}
	In recent years efforts have been made to make Machine Learning (ML) a larger part of the toolkit available to high energy physicists. ML techniques such as Boosted Decision Trees, Multivariate Analysis and Deep Learning are being used or actively researched for use in HEP in the current day. Neural networks, in particular, have already seen an application in tasks like event classification, object reconstruction, and they have been tested for potential use in triggering systems at HEP experiments. This report will concentrate specifically on Deep Learning using mostly convolutional neural networks (NN) with deep, fully connected layers. The motivation for our approach is the crucial capability of NN's to efficiently model complex, non-linear relationships in the solution of both regression and classification problems.\par
	Our approach focuses on both of these problems, in the context of reconstructing photon events in a highly granular calorimeter geometry, and the classification of signals ($\gamma$ events) against background ($\pi^{0}$ events).\par 
	
	Our methodology, as discussed later in more detail, involved training and carrying out inferences using neural networks that were either trained to do regression or classification. A separate set of \q{hybrid} networks was also created to tackle both problems simultaneously. The classification and regression performances of the hybrid and singular networks have been compared in later sections. The hybrid network approach has been attempted since it avoids the need to train two similarly structured isolated networks. In a hybrid network that attempts both operations, it is expected that the considering more than one of the features of the inputs would give such neural networks an advantage in terms of \q{visualizing} what images of signals against background correspond to specific energies of hits for a given kind of particle. This would thus allow the network to correlate both the energy of hits and particle classification to input \q{images}, potentially improving physics sensitivity. \par
	
	
	
		 
	\section{Experimental Setup and Dataset}
	Initial prototyping, and final inference processes of neural network topologies were performed on the NVIDIA GeForce 900 series GTX TitanX graphics processing units (GPU), built on the 28 nm Maxwell architecture, coupled with the Intel Core i7-5960X CPU. Given the large sizes of the dataset, the memory size of the TitanX was beneficial in allowing for large batch sizes in the training process of our network topologies.
	
	Our dataset is stored in the compressed HDF5 format. Two keys are assigned for \q{images}, which are the readouts for a given event in the ECAL and HCAL. Corresponding to each event, \q{target} keys are also assigned which detail, in increasing order of column number, particle type - 0 for pions and 1 for photons, recorded energy of the hit, and the momentum 3-vector. Given the large number of events in the dataset, the compressed nature of the HDF5 file format was essential in reducing disk usage.
	
	At the time of training, images and targets were fed into the neural networks with the aid of a data generator. In working with small datasets, it is often more convenient to load an entire dataset onto memory during training, but for a large dataset like the CaloImaging dataset (***NAME tbd***), this is not possible. In our case, it was advantageous to use a custom designed data-generator that creates an archive of pre-processed data files. Given a batch size during the training call, events are fed into a batch individually till the batch sie for training is satisfied, at which time a single batch is yielded to the model for training. Thus, at any given time, only one of all the files in the dataset is open, reducing load on the memory. 
	
	\section{Methodology}
	
	At a fundamental level, the input layer of any neural network is 
	Fundamentally,the training  training neural network topologies on inputs from a dataset with event readouts for both an Electromagnetic Calorimeter (ECAL) and Hadronic Calorimeter (HCAL), while providing corresponding target value(s) - particle ID and/or energy of the registered hit. Given several samples to train on the neural network begins to learn what signals at different energies "look" like, or how a photon shower looks compared to a $\pi^0$ showers.\par 
	Inference is carried out on relevant test samples, previously unseen to the networks during the training and validation processes. It is imperative that the inferences are carried out on unseen samples both to qualitatively measure and compare performance of different performances, and to ensure that overfitting of neural networks did not occur in the training process. 	
	
	
	\section{Energy Regression}
	Neural networks were used to carrying out regression analy
	
	\subsection{Methods}
	
	
	\subsection{Results}
	
	
	\section{Particle Classification}
	
	
	\subsection{Methods}
	
	
	\subsection{Results}
	
	
	\section{Energy Regression and Particle Classification}
	
	
	\subsection{Methods}
	
	
	\subsection{Results}
	
	
	\section{Conclusion and Future Possibilities}
	
	
	\section{Acknowledgments}
	
	
	\bibliographystyle{apsrev4-1} % Tell bibtex which bibliography style to use
	%	\bibliography{KaustuvDatta/progress_report} 
	\begin{thebibliography}
		{}
		\bibitem{baldi}
		P. Baldi, et al., Nat. Commun. 5:4308 (2014).	
		\bibitem{baldi 2}
		P.Baldi, et al.,Eur. Phys. J. C 76: 235 (2016).
		
	\end{thebibliography}
\end{document}
